from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
import pandas as pd
import numpy as np

# Ensure X_scaled is available from previous steps (K-Means or Neural Network data preparation)
if 'X_scaled' not in locals():++++
    print("X_scaled not found. Scaling data now...")
    # Assuming 'data_encoded' is available, re-prepare data if necessary
    if 'data_encoded' not in locals():
        data_encoded = pd.get_dummies(data, columns=['Product Category', 'Payment Method', 'Gender'], drop_first=True)
        data_encoded = data_encoded.drop(['Customer ID', 'Customer Name', 'Purchase Date'], axis=1)

    # Define features (X) for clustering
    X = data_encoded.drop('Churn', axis=1)

    # Scale the features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

# Sample the data to reduce execution time for DBSCAN
sample_fraction = 0.1 # Use 10% of the data for faster processing
sampled_indices_dbscan = np.random.choice(X_scaled.shape[0], int(X_scaled.shape[0] * sample_fraction), replace=False)
X_scaled_sampled_dbscan = X_scaled[sampled_indices_dbscan]
data_with_dbscan_clusters_sampled = data_encoded.iloc[sampled_indices_dbscan].copy()

# DBSCAN parameters
# eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.
# min_samples: The number of samples (or total weight) in a neighborhood for a point to be considered as a core point.
dbscan_model = DBSCAN(eps=0.5, min_samples=5)

# Fit the model and predict clusters on the sampled data
clusters_dbscan = dbscan_model.fit_predict(X_scaled_sampled_dbscan)

# Add cluster labels to the sampled DataFrame for analysis
data_with_dbscan_clusters_sampled['DBSCAN_Cluster'] = clusters_dbscan

print(f"Distribution of customers across DBSCAN clusters (on sampled data):")
display(data_with_dbscan_clusters_sampled['DBSCAN_Cluster'].value_counts().sort_index())

# Visualize the clusters
# Since the data is high-dimensional, we'll use PCA for dimensionality reduction for visualization
pca = PCA(n_components=2) # Reduce to 2 dimensions for plotting
X_pca_sampled = pca.fit_transform(X_scaled_sampled_dbscan)

plt.figure(figsize=(10, 8))
sns.scatterplot(x=X_pca_sampled[:, 0], y=X_pca_sampled[:, 1], hue=data_with_dbscan_clusters_sampled['DBSCAN_Cluster'], palette='viridis', legend='full', s=50, alpha=0.7)
plt.title('DBSCAN Clusters (PCA-reduced Sampled Data)')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()
