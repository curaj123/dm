from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Scale the features before applying K-Means
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters (e.g., using Elbow Method or Silhouette Score)
# For demonstration, let's assume we want 3 clusters.
n_clusters = 3
kmeans_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10) # n_init is set to 10 to suppress future warnings

# Fit the model and predict clusters
clusters = kmeans_model.fit_predict(X_scaled)

# Add cluster labels to the original (encoded) DataFrame for analysis
data_with_clusters = data_encoded.copy()
data_with_clusters['Cluster'] = clusters

# Display the count of customers in each cluster
print(f"Distribution of customers across {n_clusters} clusters:")
display(data_with_clusters['Cluster'].value_counts().sort_index())

# Optional: Visualize the clusters (e.g., using a scatter plot for some features if data was 2D/3D)
# For high-dimensional data, PCA/t-SNE would be needed for effective visualization.
# Let's show a simple bar plot of cluster sizes.
plt.figure(figsize=(8, 6))
sns.countplot(x='Cluster', data=data_with_clusters, palette='viridis')
plt.title('Customer Count Per Cluster')
plt.xlabel('Cluster')
plt.ylabel('Number of Customers')
plt.show()
